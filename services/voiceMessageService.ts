// cita-rd/services/voiceMessageService.ts
import { storage } from './firebase';
import { ref, uploadBytes, getDownloadURL } from 'firebase/storage';

export class VoiceRecorder {
  private mediaRecorder: MediaRecorder | null = null;
  private audioChunks: Blob[] = [];
  private stream: MediaStream | null = null;
  private startTime: number = 0;
  public onDataAvailable?: (duration: number, audioBlob: Blob) => void;
  public onError?: (error: Error) => void;

  constructor(
    onDataAvailable?: (duration: number, audioBlob: Blob) => void,
    onError?: (error: Error) => void
  ) {
    this.onDataAvailable = onDataAvailable;
    this.onError = onError;
  }

  // Iniciar grabaci√≥n
  async startRecording(): Promise<void> {
    try {
      console.log('üé§ Iniciando grabaci√≥n de voz...');
      
      // Solicitar permisos de micr√≥fono
      this.stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });

      // Configurar MediaRecorder
      this.mediaRecorder = new MediaRecorder(this.stream, {
        mimeType: 'audio/webm;codecs=opus'
      });

      this.audioChunks = [];
      this.startTime = Date.now();

      // Eventos del MediaRecorder
      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data);
        }
      };

      this.mediaRecorder.onstop = () => {
        console.log('üé§ üìã MediaRecorder.onstop evento disparado');
        const duration = Math.floor((Date.now() - this.startTime) / 1000);
        const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
        
        console.log('üé§ ‚úÖ Grabaci√≥n completada:');
        console.log('üé§   - Duraci√≥n:', duration, 'segundos');
        console.log('üé§   - Chunks:', this.audioChunks.length);
        console.log('üé§   - Blob size:', audioBlob.size, 'bytes');
        console.log('üé§   - Blob type:', audioBlob.type);
        
        // Ejecutar callback
        console.log('üé§ üìû Ejecutando callback onDataAvailable...');
        this.onDataAvailable?.(duration, audioBlob);
        console.log('üé§ ‚úÖ Callback ejecutado');
        
        // Limpiar stream
        if (this.stream) {
          console.log('üé§ üßπ Limpiando stream...');
          this.stream.getTracks().forEach(track => {
            track.stop();
            console.log('üé§   - Track detenido:', track.kind);
          });
          this.stream = null;
          console.log('üé§ ‚úÖ Stream limpiado');
        }
      };

      this.mediaRecorder.onerror = (event) => {
        console.error('‚ùå Error en grabaci√≥n:', event);
        this.onError?.(new Error('Error durante la grabaci√≥n'));
      };

      // Iniciar grabaci√≥n
      this.mediaRecorder.start();
      console.log('üé§ Grabaci√≥n iniciada');

    } catch (error) {
      console.error('‚ùå Error iniciando grabaci√≥n:', error);
      this.onError?.(error as Error);
      throw error;
    }
  }

  // Detener grabaci√≥n
  stopRecording(): void {
    if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
      console.log('üé§ üõë VoiceRecorder.stopRecording() - MediaRecorder encontrado');
      console.log('üé§ Estado actual:', this.mediaRecorder.state);
      this.mediaRecorder.stop();
      console.log('üé§ ‚úÖ MediaRecorder.stop() llamado');
    } else {
      console.error('‚ùå MediaRecorder no disponible o no est√° grabando');
      console.log('üé§ MediaRecorder:', this.mediaRecorder);
      console.log('üé§ Estado:', this.mediaRecorder?.state);
    }
  }

  // Cancelar grabaci√≥n
  cancelRecording(): void {
    if (this.mediaRecorder) {
      console.log('üé§ Cancelando grabaci√≥n...');
      this.mediaRecorder.stop();
      this.audioChunks = [];
    }
    
    if (this.stream) {
      this.stream.getTracks().forEach(track => track.stop());
      this.stream = null;
    }
  }

  // Verificar si est√° grabando
  isRecording(): boolean {
    return this.mediaRecorder?.state === 'recording';
  }

  // Obtener duraci√≥n actual
  getCurrentDuration(): number {
    if (this.startTime > 0) {
      return Math.floor((Date.now() - this.startTime) / 1000);
    }
    return 0;
  }
}

// Subir archivo de voz a Firebase Storage
export const uploadVoiceMessage = async (
  audioBlob: Blob, 
  chatId: string, 
  senderId: string
): Promise<string> => {
  try {
    console.log('‚òÅÔ∏è Subiendo mensaje de voz...');
    console.log('‚òÅÔ∏è Blob size:', audioBlob.size, 'bytes');
    console.log('‚òÅÔ∏è Chat ID:', chatId);
    console.log('‚òÅÔ∏è Sender ID:', senderId);
    
    // TEMPORAL: Crear URL local para desarrollo
    // En producci√≥n, usar Firebase Storage real
    const localUrl = URL.createObjectURL(audioBlob);
    console.log('‚òÅÔ∏è ‚úÖ URL local creada:', localUrl);
    
    // Simular delay de subida
    await new Promise(resolve => setTimeout(resolve, 500));
    
    console.log('‚òÅÔ∏è ‚úÖ Mensaje de voz "subido" (modo desarrollo)');
    return localUrl;
    
    /* C√ìDIGO ORIGINAL PARA PRODUCCI√ìN:
    const fileName = `voice_messages/${chatId}/${senderId}_${Date.now()}.webm`;
    const storageRef = ref(storage, fileName);
    
    // Subir archivo
    const snapshot = await uploadBytes(storageRef, audioBlob);
    
    // Obtener URL de descarga
    const downloadURL = await getDownloadURL(snapshot.ref);
    
    console.log('‚úÖ Mensaje de voz subido:', downloadURL);
    return downloadURL;
    */
    
  } catch (error) {
    console.error('‚ùå Error subiendo mensaje de voz:', error);
    throw error;
  }
};

// Reproducir mensaje de voz
export class VoicePlayer {
  private audio: HTMLAudioElement | null = null;
  private onPlay?: () => void;
  private onPause?: () => void;
  private onEnded?: () => void;
  private onTimeUpdate?: (currentTime: number, duration: number) => void;

  constructor(
    onPlay?: () => void,
    onPause?: () => void,
    onEnded?: () => void,
    onTimeUpdate?: (currentTime: number, duration: number) => void
  ) {
    this.onPlay = onPlay;
    this.onPause = onPause;
    this.onEnded = onEnded;
    this.onTimeUpdate = onTimeUpdate;
  }

  // Reproducir audio
  async play(audioUrl: string): Promise<void> {
    try {
      if (this.audio) {
        this.audio.pause();
      }

      this.audio = new Audio(audioUrl);
      
      // Eventos del audio
      this.audio.onplay = () => {
        console.log('üîä Reproduciendo mensaje de voz');
        this.onPlay?.();
      };

      this.audio.onpause = () => {
        console.log('‚è∏Ô∏è Mensaje de voz pausado');
        this.onPause?.();
      };

      this.audio.onended = () => {
        console.log('‚úÖ Mensaje de voz terminado');
        this.onEnded?.();
      };

      this.audio.ontimeupdate = () => {
        if (this.audio) {
          this.onTimeUpdate?.(this.audio.currentTime, this.audio.duration);
        }
      };

      await this.audio.play();
      
    } catch (error) {
      console.error('‚ùå Error reproduciendo mensaje de voz:', error);
      throw error;
    }
  }

  // Pausar audio
  pause(): void {
    if (this.audio) {
      this.audio.pause();
    }
  }

  // Detener audio
  stop(): void {
    if (this.audio) {
      this.audio.pause();
      this.audio.currentTime = 0;
    }
  }

  // Verificar si est√° reproduciendo
  isPlaying(): boolean {
    return this.audio ? !this.audio.paused : false;
  }

  // Obtener duraci√≥n
  getDuration(): number {
    return this.audio?.duration || 0;
  }

  // Obtener tiempo actual
  getCurrentTime(): number {
    return this.audio?.currentTime || 0;
  }

  // Establecer tiempo
  setCurrentTime(time: number): void {
    if (this.audio) {
      this.audio.currentTime = time;
    }
  }
}

// Formatear duraci√≥n en MM:SS
export const formatDuration = (seconds: number): string => {
  const mins = Math.floor(seconds / 60);
  const secs = Math.floor(seconds % 60);
  return `${mins}:${secs.toString().padStart(2, '0')}`;
};